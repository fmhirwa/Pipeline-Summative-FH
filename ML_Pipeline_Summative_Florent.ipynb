{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyjOhJj1rX1nI0b8YrakHz"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Pipeline Summative**"
      ],
      "metadata": {
        "id": "fAeJHzl1fndK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get mnist dataset from Kaggle. Add to runtime."
      ],
      "metadata": {
        "id": "54hApaNL6Cpw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Temp fixes for encoding\n",
        "import os\n",
        "os.environ['PYTHONIOENCODING'] = 'utf-8'\n",
        "\n",
        "import sys\n",
        "#sys.stdout.reconfigure(encoding='utf-8')\n",
        "\n",
        "# Load and preprocess MNIST data\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import layers, regularizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Load MNIST data functions\n",
        "def load_images(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        magic, num, rows, cols = np.frombuffer(f.read(16), dtype=np.uint32).byteswap()\n",
        "        images = np.frombuffer(f.read(), dtype=np.uint8).reshape(num, rows, cols)\n",
        "    return images\n",
        "\n",
        "def load_labels(file_path):\n",
        "    with open(file_path, 'rb') as f:\n",
        "        magic, num = np.frombuffer(f.read(8), dtype=np.uint32).byteswap()\n",
        "        labels = np.frombuffer(f.read(), dtype=np.uint8)\n",
        "    return labels\n",
        "\n",
        "# Load training and testing data\n",
        "train_images = load_images('./archive/train-images.idx3-ubyte')\n",
        "train_labels = load_labels('./archive/train-labels.idx1-ubyte')\n",
        "test_images = load_images('./archive/t10k-images.idx3-ubyte')\n",
        "test_labels = load_labels('./archive/t10k-labels.idx1-ubyte')\n",
        "\n",
        "# Normalize pixel values\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# Expand dimensions\n",
        "train_images = train_images[..., np.newaxis]\n",
        "test_images = test_images[..., np.newaxis]\n",
        "\n",
        "# 2. Data Augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1\n",
        ")\n",
        "datagen.fit(train_images)\n",
        "\n",
        "# 3. Define CNN model\n",
        "model = tf.keras.Sequential([\n",
        "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1), kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.2),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01)),\n",
        "    layers.Dropout(0.4),\n",
        "    layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Early stopping and learning rate reduction\n",
        "early_stopping = EarlyStopping(monitor='val_accuracy', patience=3, restore_best_weights=True)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2)\n",
        "\n",
        "# 4. Train the model\n",
        "history = model.fit(\n",
        "    datagen.flow(train_images, train_labels, batch_size=64),\n",
        "    epochs=100,  # Low for faster training\n",
        "    validation_data=(test_images, test_labels),\n",
        "    callbacks=[early_stopping, reduce_lr]\n",
        ")\n",
        "\n",
        "# 5. Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=2)\n",
        "print(f\"\\nTest accuracy: {test_acc}\")\n",
        "\n",
        "# Save model in recommended Keras format\n",
        "model.save('./saved_models/mnist_model.keras')\n",
        "\n",
        "# 6. Generate predictions\n",
        "y_pred = model.predict(test_images)\n",
        "y_pred_classes = y_pred.argmax(axis=1)\n",
        "\n",
        "# Calculate Precision, Recall, and F1 Score\n",
        "precision = precision_score(test_labels, y_pred_classes, average='weighted')\n",
        "recall = recall_score(test_labels, y_pred_classes, average='weighted')\n",
        "f1 = f1_score(test_labels, y_pred_classes, average='weighted')\n",
        "\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "\n",
        "# Directory for plots\n",
        "output_dir = './output_plots'\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Plot accuracy and loss\n",
        "def plot_and_save(history, output_dir):\n",
        "    # Accuracy plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(output_dir, 'accuracy_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "    # Loss plot\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(output_dir, 'loss_plot.png'))\n",
        "    plt.close()\n",
        "\n",
        "# Plot confusion matrix\n",
        "def plot_confusion_matrix_and_save(test_labels, y_pred_classes, output_dir):\n",
        "    conf_matrix = confusion_matrix(test_labels, y_pred_classes)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    plt.imshow(conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.colorbar()\n",
        "    plt.ylabel('True Label')\n",
        "    plt.xlabel('Predicted Label')\n",
        "\n",
        "    # Add text annotations\n",
        "    for i in range(conf_matrix.shape[0]):\n",
        "        for j in range(conf_matrix.shape[1]):\n",
        "            plt.text(j, i, format(conf_matrix[i, j], 'd'),\n",
        "                     ha=\"center\", va=\"center\",\n",
        "                     color=\"white\" if conf_matrix[i, j] > conf_matrix.max() / 2. else \"black\")\n",
        "\n",
        "    plt.savefig(os.path.join(output_dir, 'confusion_matrix.png'))\n",
        "    plt.close()\n",
        "\n",
        "# Generate and save plots\n",
        "plot_and_save(history, output_dir)\n",
        "plot_confusion_matrix_and_save(test_labels, y_pred_classes, output_dir)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "tSSkjE0t5-YM",
        "outputId": "1607b653-869f-419f-b37f-f858d2660baf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: './archive/train-images.idx3-ubyte'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ba72e8be6b1e>\u001b[0m in \u001b[0;36m<cell line: 31>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m# Load training and testing data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./archive/train-images.idx3-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./archive/train-labels.idx1-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./archive/t10k-images.idx3-ubyte'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-ba72e8be6b1e>\u001b[0m in \u001b[0;36mload_images\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# 1. Load MNIST data functions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteswap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './archive/train-images.idx3-ubyte'"
          ]
        }
      ]
    }
  ]
}